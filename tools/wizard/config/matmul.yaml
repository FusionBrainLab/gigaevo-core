# Matrix Multiplication Tensor Decomposition Problem Configuration
# Example configuration for the wizard scaffolding system
#
# This is based on the alphaevolve_math_problems/matmul problem.

name: "matmul"
description: "Matrix multiplication tensor decomposition for n=2, m=4, p=5 to minimize rank"

# Function signatures
entrypoint:
  params: []
  returns: "(decomposition, n, m, p, loss, rank) where decomposition = (U, V, W) factor matrices"
  inputs: null

validation:
  params: ["decomposition", "n", "m", "p", "loss", "rank"]
  returns: "dict with metrics: combined_score, loss, rank, is_valid"
  inputs: "decomposition: tuple of factor matrices from entrypoint(), n,m,p: ints, loss: float, rank: int"

# Metrics (is_valid is auto-generated, don't include it)
metrics:
  combined_score:
    description: "Inverse rank benchmark: 32 / rank (PRIMARY OBJECTIVE - maximize, > 1 means new record)"
    decimals: 5
    is_primary: true
    higher_is_better: true
    lower_bound: 0.0
    upper_bound: 2.0
    include_in_prompts: true
    significant_change: 0.00001
    sentinel_value: 0.0
  loss:
    description: "Final reconstruction loss (must be <= 1e-6 for success)"
    decimals: 10
    is_primary: false
    higher_is_better: false
    lower_bound: 0.0
    upper_bound: 1.0
    include_in_prompts: true
    significant_change: 0.0000000001
    sentinel_value: 1.0
  rank:
    description: "Rank of the discovered tensor decomposition"
    decimals: 0
    is_primary: false
    higher_is_better: false
    lower_bound: 1
    upper_bound: 1000
    include_in_prompts: true
    significant_change: 1
    sentinel_value: 1000

# Task description
task_description:
  objective: |
    TASK DEFINITION - MATRIX MULTIPLICATION TENSOR DECOMPOSITION (n=2, m=4, p=5)

    Problem Type: Computational Linear Algebra and Tensor Decomposition
    Challenge: Discover the lowest-rank tensor decomposition of the fixed matrix multiplication tensor for n=2, m=4, p=5.

    PROBLEM CONTEXT:
    Target: Find the minimal rank R for tensors U, V, W such that T_ijk = sum_{r=1..R} U_ir V_jr W_kr exactly reconstructs the matrix multiplication tensor.
    Benchmark: Googleâ€™s best known algorithm achieves rank 32 (combined_score = 32 / rank, PRIMARY OBJECTIVE - maximize).
    Constraint: The reconstructed tensor must match the ground-truth tensor exactly after optimization (loss <= 1e-6).

    OBJECTIVE:
    Implement a Python function that returns the factor matrices (U, V, W), tensor dimensions, loss, and rank such that:
    - decomposition = (U, V, W) with shapes (n*m, rank), (m*p, rank), (n*p, rank)
    - Tensor reconstruction equals the standard matrix multiplication tensor
    - Rank is as small as possible

    PERFORMANCE METRICS:
    - combined_score = 32 / rank (PRIMARY OBJECTIVE - maximize)
    - loss (must be near zero for a valid solution)
    - rank (integer)

    VALIDATION REQUIREMENTS:
    - Verify factor matrix shapes
    - Reconstruct tensor via einsum and ensure exact equality with matmul tensor
    - Check rank is integer and loss <= 1e-6

    HINTS & STRATEGY:
    - Use staged optimization (continuous search -> discrete rounding)
    - Enforce constraints via custom rounding, clipping, or search over discrete grids
    - Explore schedule/learning rate trade-offs and random restarts
    - Ensure reproducibility with fixed seeds

  hints:
    - "Shape validation: Ensure U, V, W have shapes (n*m, rank), (m*p, rank), (n*p, rank)"
    - "Exact tensor match: reconstructed tensor must equal matmul tensor element-wise"
    - "Loss threshold: enforce loss <= 1e-6 for success"
    - "Rank minimization: combined_score = 32 / rank so lower rank yields higher score"
    - "Initialization sensitivity: multiple restarts or heuristic warm starts help"
    - "Discrete rounding: use STE or grid search to snap factors to valid values"
    - "Numerical stability: consider gradient clipping or normalization"

# Optional features
add_context: false
add_helper: true

# Initial programs
initial_programs:
  - name: "jax_optimizer"
    description: "Two-phase JAX optimization with straight-through rounding"
  - name: "random_factors"
    description: "Random factor initialization with quick loss check"
  - name: "low_rank_search"
    description: "Grid/heuristic search over low-rank factor candidates"
